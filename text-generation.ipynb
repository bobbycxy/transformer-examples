{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 12:22:20.543739: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-23 12:22:21.075965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import os \n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_LEN = 500\n",
    "DECODER_LEN = 100\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = BATCH_SIZE*8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bobby/code-repo/practices/transformer-examples/env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/bobby/code-repo/practices/transformer-examples/env/lib/python3.8/site-packages/datasets/load.py:1454: FutureWarning: The repository for xsum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/xsum\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"xsum\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = raw_datasets.train_test_split(\n",
    "    train_size=0.1, test_size=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "      <th>train test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sir Iain Lobban will leave later this year, af...</td>\n",
       "      <td>The head of GCHQ - Britain's electronic intell...</td>\n",
       "      <td>25937478</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The bank's quarterly sectoral forecast said im...</td>\n",
       "      <td>The Northern Ireland economy should grow at 2....</td>\n",
       "      <td>27943149</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Developed countries agreed to stop the subsidi...</td>\n",
       "      <td>Countries in the World Trade Organization (WTO...</td>\n",
       "      <td>35145377</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They were trying to explain why the animals ha...</td>\n",
       "      <td>Elephants have enhanced defences against cance...</td>\n",
       "      <td>34466220</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The new one will have 12 sides instead of a sm...</td>\n",
       "      <td>Pocket money may look a bit different this tim...</td>\n",
       "      <td>35935007</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20399</th>\n",
       "      <td>It has advised all international postal servic...</td>\n",
       "      <td>The Republic of Ireland's postal service An Po...</td>\n",
       "      <td>34426129</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20400</th>\n",
       "      <td>It's a kind of all-purpose, good-for-all-occas...</td>\n",
       "      <td>The phrase \"out of touch political elite\" trip...</td>\n",
       "      <td>36562167</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20401</th>\n",
       "      <td>Rachel and Nyomi Fee deny murdering two-year-o...</td>\n",
       "      <td>Evidence of untreated injuries found on Liam F...</td>\n",
       "      <td>36370492</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20402</th>\n",
       "      <td>The move, expected since December, also sees B...</td>\n",
       "      <td>Valtteri Bottas has succeeded retired world ch...</td>\n",
       "      <td>38489054</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20403</th>\n",
       "      <td>Gary Madine headed in Josh Vela's cross to giv...</td>\n",
       "      <td>Bolton Wanderers thumped Gillingham to move ba...</td>\n",
       "      <td>38204525</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20404 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                document  \\\n",
       "0      Sir Iain Lobban will leave later this year, af...   \n",
       "1      The bank's quarterly sectoral forecast said im...   \n",
       "2      Developed countries agreed to stop the subsidi...   \n",
       "3      They were trying to explain why the animals ha...   \n",
       "4      The new one will have 12 sides instead of a sm...   \n",
       "...                                                  ...   \n",
       "20399  It has advised all international postal servic...   \n",
       "20400  It's a kind of all-purpose, good-for-all-occas...   \n",
       "20401  Rachel and Nyomi Fee deny murdering two-year-o...   \n",
       "20402  The move, expected since December, also sees B...   \n",
       "20403  Gary Madine headed in Josh Vela's cross to giv...   \n",
       "\n",
       "                                                 summary        id train test  \n",
       "0      The head of GCHQ - Britain's electronic intell...  25937478      train  \n",
       "1      The Northern Ireland economy should grow at 2....  27943149      train  \n",
       "2      Countries in the World Trade Organization (WTO...  35145377      train  \n",
       "3      Elephants have enhanced defences against cance...  34466220      train  \n",
       "4      Pocket money may look a bit different this tim...  35935007      train  \n",
       "...                                                  ...       ...        ...  \n",
       "20399  The Republic of Ireland's postal service An Po...  34426129      train  \n",
       "20400  The phrase \"out of touch political elite\" trip...  36562167      train  \n",
       "20401  Evidence of untreated injuries found on Liam F...  36370492      train  \n",
       "20402  Valtteri Bottas has succeeded retired world ch...  38489054      train  \n",
       "20403  Bolton Wanderers thumped Gillingham to move ba...  38204525      train  \n",
       "\n",
       "[20404 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(raw_datasets['train'])\n",
    "train_df['train test'] = 'train'\n",
    "\n",
    "df = pd.concat([train_df], axis = 0).reset_index(drop = True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = df['document']\n",
    "summary = df['summary']\n",
    "article = article.apply(lambda x: '<SOS> ' + x + ' <EOS>')\n",
    "summary = summary.apply(lambda x: '<SOS> ' + x + ' <EOS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r\"&.[1-9]+;\",\" \",text)\n",
    "    return text\n",
    "article = article.apply(lambda x: preprocess(x))\n",
    "summary = summary.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
    "oov_token = '<unk>'\n",
    "article_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
    "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)\n",
    "article_tokenizer.fit_on_texts(article)\n",
    "summary_tokenizer.fit_on_texts(summary)\n",
    "inputs = article_tokenizer.texts_to_sequences(article)\n",
    "targets = summary_tokenizer.texts_to_sequences(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114832 27383\n"
     ]
    }
   ],
   "source": [
    "ENCODER_VOCAB = len(article_tokenizer.word_index) + 1\n",
    "DECODER_VOCAB = len(summary_tokenizer.word_index) + 1\n",
    "print(ENCODER_VOCAB, DECODER_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 12:23:34.763485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:34.763748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:34.763961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:34.764165: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:34.772387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:34.772605: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:34.772801: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:34.772991: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:34.773179: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:34.773364: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:34.773559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:34.773748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:35.034709: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:35.034978: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:35.035187: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:35.035382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:35.035574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:35.035756: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:35.035940: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:35.036122: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:35.036303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:35.036485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:35.036663: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:35.036842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:36.215850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:36.216096: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:36.216302: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:36.216499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:36.216687: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:36.216873: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:36.217051: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:36.217230: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:36.217433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:36.217707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20624 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:81:00.0, compute capability: 8.6\n",
      "2024-02-23 12:23:36.218015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:36.218171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 20794 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:82:00.0, compute capability: 8.6\n",
      "2024-02-23 12:23:36.218382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:36.218535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 20794 MB memory:  -> device: 2, name: NVIDIA RTX A5000, pci bus id: 0000:c1:00.0, compute capability: 8.6\n",
      "2024-02-23 12:23:36.218735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-23 12:23:36.218886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 20794 MB memory:  -> device: 3, name: NVIDIA RTX A5000, pci bus id: 0000:c2:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=ENCODER_LEN, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=DECODER_LEN, padding='post', truncating='post')\n",
    "inputs = tf.cast(inputs, dtype=tf.int64)\n",
    "targets = tf.cast(targets, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 12:23:40.671777: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 81616000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(position, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
    "    return position * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(\n",
    "        np.arange(position)[:, np.newaxis],\n",
    "        np.arange(d_model)[np.newaxis, :],\n",
    "        d_model\n",
    "    )\n",
    "\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attention \n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
    "        output = self.dense(concat_attention)\n",
    "            \n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),\n",
    "        tf.keras.layers.Dense(d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "        \n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
    "\n",
    "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 8 # number of layers for the encoder and decoder\n",
    "d_model = 128 # dimension of the model\n",
    "dff = 512 # dimension of the feed-forward network\n",
    "num_heads = 8 # number of heads for the multihead attention \n",
    "dropout_rate = 0.2 # for regularization\n",
    "EPOCHS = 15 # how many times to train over the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "    #accuracies = tf.cast(accuracies, dtype= tf.float32)\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=ENCODER_VOCAB,\n",
    "    target_vocab_size=DECODER_VOCAB,\n",
    "    pe_input=1000,\n",
    "    pe_target=1000,\n",
    "    rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoints\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(\n",
    "            inp, tar_inp, \n",
    "            True, \n",
    "            enc_padding_mask, \n",
    "            combined_mask, \n",
    "            dec_padding_mask\n",
    "        )\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar_real, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-23 12:26:49.874437: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 81616000 exceeds 10% of free system memory.\n",
      "2024-02-23 12:27:05.660177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-02-23 12:27:05.833945: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbcc00422b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-23 12:27:05.833967: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2024-02-23 12:27:05.833972: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2024-02-23 12:27:05.833976: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2024-02-23 12:27:05.833979: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2024-02-23 12:27:05.843842: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-23 12:27:05.959208: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-02-23 12:27:06.070062: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 10.2330 Accuracy 0.0000\n",
      "Epoch 1 Batch 100 Loss 10.1243 Accuracy 0.0236\n",
      "Epoch 1 Batch 200 Loss 9.8981 Accuracy 0.0345\n",
      "Epoch 1 Batch 300 Loss 9.5554 Accuracy 0.0382\n",
      "Epoch 1 Loss 9.4862 Accuracy 0.0386\n",
      "Time taken for 1 epoch: 174.6761031150818 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 8.2317 Accuracy 0.0386\n",
      "Epoch 2 Batch 100 Loss 7.8067 Accuracy 0.0405\n",
      "Epoch 2 Batch 200 Loss 7.5586 Accuracy 0.0423\n",
      "Epoch 2 Batch 300 Loss 7.4361 Accuracy 0.0475\n",
      "Epoch 2 Loss 7.4218 Accuracy 0.0484\n",
      "Time taken for 1 epoch: 126.68213224411011 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 7.1615 Accuracy 0.0485\n",
      "Epoch 3 Batch 100 Loss 7.1202 Accuracy 0.0529\n",
      "Epoch 3 Batch 200 Loss 7.0934 Accuracy 0.0565\n",
      "Epoch 3 Batch 300 Loss 7.0368 Accuracy 0.0603\n",
      "Epoch 3 Loss 7.0243 Accuracy 0.0612\n",
      "Time taken for 1 epoch: 126.26662254333496 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 6.7644 Accuracy 0.0613\n",
      "Epoch 4 Batch 100 Loss 6.6688 Accuracy 0.0666\n",
      "Epoch 4 Batch 200 Loss 6.5868 Accuracy 0.0716\n",
      "Epoch 4 Batch 300 Loss 6.5066 Accuracy 0.0766\n",
      "Epoch 4 Loss 6.4932 Accuracy 0.0775\n",
      "Time taken for 1 epoch: 126.19785118103027 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 6.1876 Accuracy 0.0775\n",
      "Epoch 5 Batch 100 Loss 6.1883 Accuracy 0.0824\n",
      "Epoch 5 Batch 200 Loss 6.1564 Accuracy 0.0868\n",
      "Epoch 5 Batch 300 Loss 6.1122 Accuracy 0.0911\n",
      "Saving checkpoint for epoch 5 at checkpoints/ckpt-1\n",
      "Epoch 5 Loss 6.1050 Accuracy 0.0919\n",
      "Time taken for 1 epoch: 126.21735548973083 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 5.9219 Accuracy 0.0919\n",
      "Epoch 6 Batch 100 Loss 5.9058 Accuracy 0.0962\n",
      "Epoch 6 Batch 200 Loss 5.8874 Accuracy 0.1000\n",
      "Epoch 6 Batch 300 Loss 5.8551 Accuracy 0.1037\n",
      "Epoch 6 Loss 5.8477 Accuracy 0.1043\n",
      "Time taken for 1 epoch: 125.12019419670105 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 5.6217 Accuracy 0.1044\n",
      "Epoch 7 Batch 100 Loss 5.6920 Accuracy 0.1079\n",
      "Epoch 7 Batch 200 Loss 5.6710 Accuracy 0.1111\n",
      "Epoch 7 Batch 300 Loss 5.6407 Accuracy 0.1143\n",
      "Epoch 7 Loss 5.6339 Accuracy 0.1148\n",
      "Time taken for 1 epoch: 124.76473355293274 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 5.5099 Accuracy 0.1149\n",
      "Epoch 8 Batch 100 Loss 5.4875 Accuracy 0.1179\n",
      "Epoch 8 Batch 200 Loss 5.4699 Accuracy 0.1207\n",
      "Epoch 8 Batch 300 Loss 5.4402 Accuracy 0.1234\n",
      "Epoch 8 Loss 5.4341 Accuracy 0.1239\n",
      "Time taken for 1 epoch: 125.17119359970093 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 5.2223 Accuracy 0.1239\n",
      "Epoch 9 Batch 100 Loss 5.2992 Accuracy 0.1267\n",
      "Epoch 9 Batch 200 Loss 5.2881 Accuracy 0.1292\n",
      "Epoch 9 Batch 300 Loss 5.2589 Accuracy 0.1317\n",
      "Epoch 9 Loss 5.2542 Accuracy 0.1321\n",
      "Time taken for 1 epoch: 125.03954148292542 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 5.3324 Accuracy 0.1321\n",
      "Epoch 10 Batch 100 Loss 5.1315 Accuracy 0.1346\n",
      "Epoch 10 Batch 200 Loss 5.1270 Accuracy 0.1368\n",
      "Epoch 10 Batch 300 Loss 5.1018 Accuracy 0.1391\n",
      "Saving checkpoint for epoch 10 at checkpoints/ckpt-2\n",
      "Epoch 10 Loss 5.0969 Accuracy 0.1395\n",
      "Time taken for 1 epoch: 125.67965245246887 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 5.0710 Accuracy 0.1396\n",
      "Epoch 11 Batch 100 Loss 4.9858 Accuracy 0.1418\n",
      "Epoch 11 Batch 200 Loss 4.9744 Accuracy 0.1439\n",
      "Epoch 11 Batch 300 Loss 4.9539 Accuracy 0.1460\n",
      "Epoch 11 Loss 4.9502 Accuracy 0.1464\n",
      "Time taken for 1 epoch: 124.92711663246155 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 4.7839 Accuracy 0.1464\n",
      "Epoch 12 Batch 100 Loss 4.8463 Accuracy 0.1485\n",
      "Epoch 12 Batch 200 Loss 4.8389 Accuracy 0.1504\n",
      "Epoch 12 Batch 300 Loss 4.8234 Accuracy 0.1523\n",
      "Epoch 12 Loss 4.8200 Accuracy 0.1527\n",
      "Time taken for 1 epoch: 124.94761228561401 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 4.8414 Accuracy 0.1527\n",
      "Epoch 13 Batch 100 Loss 4.7259 Accuracy 0.1546\n",
      "Epoch 13 Batch 200 Loss 4.7186 Accuracy 0.1564\n",
      "Epoch 13 Batch 300 Loss 4.7009 Accuracy 0.1582\n",
      "Epoch 13 Loss 4.6979 Accuracy 0.1585\n",
      "Time taken for 1 epoch: 124.86787271499634 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 4.7365 Accuracy 0.1586\n",
      "Epoch 14 Batch 100 Loss 4.5980 Accuracy 0.1604\n",
      "Epoch 14 Batch 200 Loss 4.5817 Accuracy 0.1622\n",
      "Epoch 14 Batch 300 Loss 4.5585 Accuracy 0.1640\n",
      "Epoch 14 Loss 4.5552 Accuracy 0.1643\n",
      "Time taken for 1 epoch: 125.17033624649048 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 4.5555 Accuracy 0.1643\n",
      "Epoch 15 Batch 100 Loss 4.4441 Accuracy 0.1661\n",
      "Epoch 15 Batch 200 Loss 4.4378 Accuracy 0.1679\n",
      "Epoch 15 Batch 300 Loss 4.4135 Accuracy 0.1697\n",
      "Saving checkpoint for epoch 15 at checkpoints/ckpt-3\n",
      "Epoch 15 Loss 4.4110 Accuracy 0.1700\n",
      "Time taken for 1 epoch: 125.39826035499573 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "        train_step(inp, tar)\n",
    "    \n",
    "        if batch % 100 == 0:\n",
    "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "      \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
    "   \n",
    "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_article):\n",
    "    input_article = article_tokenizer.texts_to_sequences([input_article])\n",
    "    input_article = tf.keras.preprocessing.sequence.pad_sequences(input_article, maxlen=ENCODER_LEN, \n",
    "                                                                   padding='post', truncating='post')\n",
    "\n",
    "    encoder_input = tf.expand_dims(input_article[0], 0)\n",
    "\n",
    "    decoder_input = [summary_tokenizer.word_index['<sos>']]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(DECODER_LEN):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
    "\n",
    "        predictions, attention_weights = transformer(\n",
    "            encoder_input, \n",
    "            output,\n",
    "            False,\n",
    "            enc_padding_mask,\n",
    "            combined_mask,\n",
    "            dec_padding_mask\n",
    "        )\n",
    "\n",
    "        predictions = predictions[: ,-1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        if predicted_id == summary_tokenizer.word_index['<eos>']:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(input_article):\n",
    "    summarized = evaluate(input_article=input_article)[0].numpy()\n",
    "    summarized = np.expand_dims(summarized[1:], 0)  \n",
    "    return summary_tokenizer.sequences_to_texts(summarized)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS> Sir Iain Lobban will leave later this year, after six years as director.\n",
      "The Foreign Office said Sir Iain, 53, was doing \"outstanding job\" and his departure was \"planned\".\n",
      "Officials denied the move was linked to controversy over GCHQ and its US counterpart, the NSA, sparked by disclosures from former US intelligence contractor Edward Snowden.\n",
      "Sir Iain, who first joined GCHQ in 1983, became director in June 2008.\n",
      "\"Today is simply about starting the process of ensuring we have a suitable successor in place before he moves on as planned at the end of the year,\" a Foreign Office spokesman said.\n",
      "ln November, Sir Iain became the first head of the agency to give evidence in public when he appeared before MPs on the Intelligence and Security Committee, alongside the heads of MI5 and MI6.\n",
      "They came under pressure to be more open after leaks by Mr Snowden revealed widespread spying by GCHQ and the US National Security Agency.\n",
      "Sir Iain told the committee Mr Snowden's disclosures had done immense damage to Britain's counter-terrorism efforts.\n",
      "MPs asked Sir Iain why he felt it was necessary to \"collect information on the majority of the public in order to protect us from a minority of evildoers\".\n",
      "He said GCHQ did not spend its time \"listening to the telephone calls or reading the emails of the majority\" of the public. <EOS>\n"
     ]
    }
   ],
   "source": [
    "print(article[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Headline :  <SOS> The head of GCHQ - Britain's electronic intelligence gathering agency - is to step down, the Foreign Office has said. <EOS> \n",
      " Predicted Summary :  the uk is to be the first of the first time in the uk to pay the uk to pay jobs in the uk\n"
     ]
    }
   ],
   "source": [
    "print(\"Real Headline : \", summary[0],\"\\n Predicted Summary : \", summarize(article[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
